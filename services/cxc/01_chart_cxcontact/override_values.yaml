###############################################################################
# Global CX Concact parameters
# https://all.docs.genesys.com/PEC-OU/Current/CXCPEGuide/Configure
###############################################################################

image:
  registry: $IMAGE_REGISTRY/cxcontact
  imagePullSecrets:
    - name: pullsecret

cxcontact:

  replicas: 1
  log:
    level: info

  deployDefaultInitContainer: false

  compliance_data:
    cdp_ng:
      url: "https://api.usw2.pure.cloud/api/v2/outbound/compliancedata"
      gcloud_auth: "https://login.usw2.pure.cloud/oauth/token"
      gcloud_id: $cxc_cdp_gcloud_id
      gcloud_secret: $cxc_cdp_gcloud_secret

#  override:                #if connecting to Nexus. Otherwise Dial Manager is off
#    dial-manager:
#      enabled: false
#      nexus:
#        host: ..
#        port: ..
#      api_key: ..          #required

monitoring:
  enabled: true
  dashboards: true
  alarms: true
  pagerduty: false

k8s_optional:
  podSecurityContext: {}
  # dnsDomain will be used for generating FQDN for k8s services, for e.g "http://cxc-list-manager.cxc.svc.cluster.local."
  dnsDomain: ".svc.${DNS_SCOPE}."     # this is important to change in GKE if have VPC scope DNS
                                      # ex: ".svc.gke1-uswest1.gcpe002.gencpe.com"

redis:
  enabled: true
  cluster: true
  # can be comma-delimited list of redis nodes, for e.g.
  # nodes: redis://redis-node1:6379,redis://redis-node2:6379,redis://redis-node3:6379
  nodes: redis://${REDIS_ADDR}:${REDIS_PORT}
  #use_tls: false
  requirepass: true

elasticsearch:
  enabled: true
  host: http://$ES_ADDR
  port: 9200

gws:
  # GWS Ingress URL
  frontend_host: https://gauth.$DOMAIN
  frontend_port: 443


#  Services. Will be used for connection to GWS if GWS Internal Ingress URL is disabled (empty values)
  core:
    auth:
      host: http://gauth-auth.${GAUTH_NAMESPACE}
      port: 80
    environment:
      host: http://gauth-environment.${GAUTH_NAMESPACE}
      port: 80
  platform:
    ocs:
      host: http://gws-service-proxy.${GWS_NAMESPACE}
      port: 80
    configuration:
      host: http://gws-service-proxy.${GWS_NAMESPACE}
      port: 80
    statistics:
      host: http://gws-service-proxy.${GWS_NAMESPACE}
      port: 80
    setting:
      host: http://gws-service-proxy.${GWS_NAMESPACE}
      port: 80
    voice:
      host: http://gws-service-proxy.${GWS_NAMESPACE}
      port: 80


ingress:
  enabled: true
  tls_enabled: true
  cxc_frontend: cxc.$DOMAIN
  annotations:
#    !!!Ingress Session Stickiness is required.
#    Default annotations:
    nginx.ingress.kubernetes.io/affinity: cookie
    nginx.ingress.kubernetes.io/session-cookie-samesite: "Lax"
    nginx.ingress.kubernetes.io/session-cookie-name: "cxc-session-cookie"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    # For openshift. Do not change next two lines . For k8s see separate overrides file
    route.openshift.io/termination: edge
  tls: []

# Additional ingress to expose internal backend endpoints.
# If disabled  - all endpoints will be exposed on ingress.cxc_frontend
internal_ingress:
  enabled: true
  tls_enabled: false
  cxc_backend: cxc-int.$DOMAIN
  annotations:
#    Default annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/ssl-redirect: 'false'
  tls: []
  #  - hosts:
  #      - cxc-int.$DOMAIN
  #    secretName: cxc-int-tls

storage:
  # Persistent Volumes Claim Configuration
  pvc:
    enabled: true
    create: true
#    Instructs Helm to skip deleting PVC when a helm operation (such as helm uninstall, helm upgrade or helm rollback)
#    would result in its deletion. However, this resource becomes orphaned. Helm will no longer manage it in any way.
#    https://helm.sh/docs/howto/charts_tips_and_tricks/#tell-helm-not-to-uninstall-a-resource
#    If PVC is already orphaned and you want to re-use it - set `storage.pvc.create` to `false`.
    keepAfterDeletion: false
    size: 2Gi
    name: cxc-claim
    storageClassName: $STORAGE_CLASS_RWX
